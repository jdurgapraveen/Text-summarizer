
from nltk.corpus import stopwords as sw
from nltk.stem import PorterStemmer as ps
from nltk.tokenize import word_tokenize, sent_tokenize

text_string = '''
 If the coming together of the Shiv Sena, Nationalist Congress Party (NCP) and the Congress in an attempt to form a majority in the hung State Assembly was disrespectful of the mandate, the skullduggery by the dead of night was an outright mockery of democratic norms and established procedure. Pursuit of power often involves amoral ingredients, but the surreal birthing of the new government was nothing short of sheer depravity. The BJP has not set any inspiring ethical bar when it achieved power without winning a popular mandate in several States, but this new low leaves the nation’s political ‘conscience’ with a sinking feeling. In one stroke, the President, the Prime Minister, and the Governor, all appear to be not as guardians of the constitutional order but collaborators in a clandestine, nocturnal scheme. Politically indefensible as the Sena-Congress-NCP alliance might be, its claim to form a government is technically unimpeachable, and cannot be denied.
'''


def frequency_table(text_string) -> dict:
    """
    Dictionary created for word frequency table, prerequisite is after elimination of stopwords and find some root words.
   
    """
    stopWords = set(sw.words("english"))
    words = word_tokenize(text_string)
    ps = PorterStemmer()

    freqTable = dict()
    for word in words:
        word = ps.stem(word)
        if word in stopWords:
            continue
        if word in freqTable:
            freqTable[word] += 1
        else:
            freqTable[word] = 1

    return freqTable


def score_sentences(sentences, freqTable) -> dict:
    """
    Score a sentence = frequency of every non-stop word in a sentence/total no of words in a sentence
   
    """

    sentenceValue = dict()

    for sentence in sentences:
        word_count_in_sentence = (len(word_tokenize(sentence)))
        word_count_in_sentence_except_stop_words = 0
        for wordValue in freqTable:
            if wordValue in sentence.lower():
                word_count_in_sentence_except_stop_words += 1
                if sentence[:10] in sentenceValue:
                    sentenceValue[sentence[:10]] += freqTable[wordValue]
                else:
                    sentenceValue[sentence[:10]] = freqTable[wordValue]

        if sentence[:10] in sentenceValue:
            sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] / word_count_in_sentence_except_stop_words

       
    return sentenceValue


def average_score(sentenceValue) -> int:
    """
    Find the average score from the sentence value dictionary
       """
    sumValues = 0
    for entry in sentenceValue:
        sumValues += sentenceValue[entry]

    # Average value of a sentence from original text
    average = (sumValues / len(sentenceValue))

    return average


def generate_summary(sentences, sentenceValue, threshold):
    sentence_count = 0
    summary = ''

    for sentence in sentences:
        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] >= (threshold):
            summary += " " + sentence
            sentence_count += 1

    return summary


def summarization(text):
    # 1 Tokenize the sentences
    sentences = sent_tokenize(text)
    
    # 2 Create the word frequency table
    freq_table = frequency_table(text)

    # 3 score the sentences
    sentence_scores = score_sentences(sentences, freq_table)

    # 4 Find the threshold
    threshold = average_score(sentence_scores)

    # 5 Generate the summary
    summary = generate_summary(sentences, sentence_scores, 0.7 * threshold)

    return summary


if __name__ == '__main__':
    output = summarization(text_string)
    print(output)
